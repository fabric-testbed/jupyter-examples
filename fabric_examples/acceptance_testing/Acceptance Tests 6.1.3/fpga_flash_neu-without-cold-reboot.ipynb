{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Functional Test 6.1.3 - Flash NEU/OCT code into an FPGA persistent flash or RAM and validate\n",
    "\n",
    "This Jupyter notebook will allow you to flash experimenter FPGA code based on [ONS shell](https://github.com/Xilinx/open-nic-shell) into the FPGA persistent flash or RAM. If the persistent flash is used, the end result is an FPGA that even after a cold reboot of the server retains its programming with a standard Xilinx XRT shell. If the program is flashed into RAM, a warm reboot of the server will activate it. \n",
    "\n",
    "This procedure can be used to reset the FPGA at a given site after experiments or initialize a newly installed device. It generally follows the procedures described by [NEU](https://github.com/OCT-FPGA/P4OpenNIC_Public/tree/main/FABRIC-P4) for U280 devices.\n",
    "\n",
    "It is assumed you are operating as part of the FABRIC Maintenance project and have access to the persistent volume named `fpga-tools` created on EDC where releavent tools are downloaded.\n",
    "\n",
    "This notebook is broken up into steps and does not have to be executed in sequence.\n",
    "\n",
    "- Step 2 Has multiple cells that initialize fablib and variables and creates a new slice\n",
    "  - The cells initializing the state __must always be executed__.\n",
    "  - Creating a slice is optional and can be skipped if slice already exists\n",
    "- Step 3 is a re-entrant cell and can be used any time you want to refresh information about the existing slice\n",
    "- Step 4 fetches the tools from the Storage VM and installs:\n",
    "  - Xilinx Labtools\n",
    "  - experimenter-provided bitfile artifact\n",
    "- Step 5 is the actual flashing and it involves identifying and rebooting the underlying server.\n",
    "- Step 6 is an optional 'extend the slice' step that can be excuted if Steps 2 and 3 have been executed.\n",
    "- Step 7 is 'delete the slice' that can be executed any time after Steps 2 and 3 have been executed.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 2: Provision a VM on the desired worker with attached FPGA and FABNetv4 connection\n",
    "\n",
    "Create a slice with a VM attached to the FPGA on the desired site and a FABNetv4 interface to reach the Storage VM in Step 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize fablib and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize FABlib\n",
    "\n",
    "from fabrictestbed_extensions.fablib.fablib import FablibManager as fablib_manager\n",
    "\n",
    "fablib = fablib_manager()\n",
    "                     \n",
    "fablib.show_config();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define slice parameters - re-execute as needed to run any of the steps in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user artifact should be deposited Storage VM into /mnt/fpga_tools/static/artifacts/<owner username>/<version> since names of artifacts may be similar or same.\n",
    "artifact_owner_username = 'sbal'\n",
    "artifact_version = 'v1'\n",
    "\n",
    "# edit the name of the user-provided artifact and labtools and DPDK docker images stored in Storage VM as needed\n",
    "\n",
    "artifact = 'addhdr_jumbo.mcs'\n",
    "#artifact = 'rmvhdr_jumbo.mcs'\n",
    "artifact_golden = 'revert_to_golden.mcs'\n",
    "\n",
    "# Xilinx labtools package in Storage VM\n",
    "labtools_package = 'Vivado/Vivado_Lab_Lin_2023.2_1013_2256.tar.gz'\n",
    "\n",
    "# Xilinx xrt package in Storage VM\n",
    "xrt_package = 'alveo-packages/xrt_202320.2.16.204_20.04-amd64-xrt.deb'\n",
    "\n",
    "# Xilinx deployment target package in Storage VM\n",
    "deployment_tgt_package = 'alveo-packages/xilinx-u280-gen3x16-xdma_2023.2_2023_1014_0238-all.deb.tar.gz'\n",
    "\n",
    "# Xilinx xbflash2 package in Storage VM\n",
    "xbflash2_package = 'alveo-packages/xrt_202210.2.13.466_20.04-amd64-xbflash2.deb'\n",
    "\n",
    "# Pcimem configDPDK.sh script in Storage VM\n",
    "configdpdk_script = 'alveo-utilities/configDPDK.sh'\n",
    "\n",
    "# FABNetv4 of storage VM - consult the Storage VM slice for this FABNetv4 IP address\n",
    "#storage_vm_ip = \"10.131.1.2\"\n",
    "# username and password used in storage VM\n",
    "nginx_user = \"fpga_tools\"\n",
    "nginx_password = \"secret-password\"\n",
    "\n",
    "#\n",
    "# should not need to edit below\n",
    "FPGA_CHOICE='FPGA_Xilinx_U280'\n",
    "\n",
    "\n",
    "# don't edit - convert from FPGA type to a resource column name\n",
    "# to use in filter lambda function below\n",
    "choice_to_column = {\n",
    "    \"FPGA_Xilinx_U280\": \"fpga_u280_available\",\n",
    "}\n",
    "\n",
    "column_name = choice_to_column.get(FPGA_CHOICE, \"Unknown\")\n",
    "\n",
    "fpga_bdf = \"0000:1f:00.0\"\n",
    "\n",
    "#fablib.get_image_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup site name\n",
    "site='RENC'\n",
    "node_name='fpga-node'\n",
    "\n",
    "# name the slice and the node \n",
    "slice_name=f'Persistent slice with {FPGA_CHOICE} on {site}'\n",
    "print(f'Will create slice \"{slice_name}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new slice \n",
    "\n",
    "Create a slice with FPGA component on selected site and access to FABNetv4 network.\n",
    "\n",
    "__NOTE:__ It is important to use a Docker-enabled image so that Docker can properly build docker images on IPv6-enabled sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Slice. Note that by default submit() call will poll for 360 seconds every 10-20 seconds\n",
    "# waiting for slice to come up. Normal expected time is around 2 minutes. \n",
    "slice = fablib.new_slice(name=slice_name)\n",
    "image = 'docker_ubuntu_20'\n",
    "\n",
    "# Add node with a 200G drive and 8 of CPU cores using Ubuntu 20 image\n",
    "node = slice.add_node(name=node_name, site=site, cores=8, disk=200, image=image)\n",
    "node.add_component(model=FPGA_CHOICE, name='fpga1')\n",
    "# be sure to add FABNetv4 so we can communicate with the slice that has the tools\n",
    "node.add_fabnet()\n",
    "\n",
    "# use the postboot script from docker examples\n",
    "node.add_post_boot_upload_directory('../../fablib_api/docker_containers/node_tools','.')\n",
    "node.add_post_boot_execute('node_tools/enable_docker.sh {{ _self_.image }} ')\n",
    "node.add_post_boot_upload_directory('node_config','.')\n",
    "node.add_post_boot_execute(f'chmod a+x node_config/ipv6-and-docker-plugins.sh && node_config/ipv6-and-docker-plugins.sh')\n",
    "\n",
    "# Submit Slice Request\n",
    "slice.submit();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Inspect the slice\n",
    "Note that nat64 configuration is done at boot time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = fablib.get_slice(slice_name)\n",
    "\n",
    "node = slice.get_node(name=node_name)              \n",
    "\n",
    "node_addr = node.get_interface(network_name=f'FABNET_IPv4_{node.get_site()}').get_ip_addr()\n",
    "\n",
    "slice.show()\n",
    "slice.list_nodes()\n",
    "slice.list_networks()\n",
    "print(f'Node FABNetV4 IP Address is {node_addr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 4: Fetch Tools and Install Vivado Lab\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Fetch the Linux tools from Xilinx and place into appropriate location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 4.1.1 Clone OCT-FPGA repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkout the repo\n",
    "\n",
    "#\n",
    "# This repo is forked from https://github.com/OCT-FPGA/P4OpenNIC_Public.git\n",
    "# program_flash.tcl is modified to include commands for booting from the \n",
    "# configuration memory device\n",
    "#\n",
    "\n",
    "tools_neu_repo = 'https://github.com/mcevik0/P4OpenNIC_Public.git'\n",
    "\n",
    "commands = list()\n",
    "commands.append(f'[ ! -d ~/fpga-tools ] && mkdir -p ~/fpga-tools')\n",
    "commands.append(f'cd fpga-tools && git clone {tools_neu_repo} && cd P4OpenNIC_Public && git checkout fpga-flash-boot-from-config-mem')\n",
    "\n",
    "for command in commands:\n",
    "    print(f'Executing {command}')\n",
    "    stdout, stderr = node.execute(command)\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 4.1.2 Clone pcimem repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkout the repo\n",
    "\n",
    "# checkout the repo\n",
    "pcimem_repo = 'https://github.com/billfarrow/pcimem.git'\n",
    "\n",
    "commands = list()\n",
    "commands.append(f'[ ! -d ~/fpga-tools ] && mkdir -p fpga-tools')\n",
    "commands.append(f'cd fpga-tools && git clone {pcimem_repo}')\n",
    "\n",
    "for command in commands:\n",
    "    print(f'Executing {command}')\n",
    "    stdout, stderr = node.execute(command)\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.3 Copy configDPDK.sh from the Storage VM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "tools_location = '~/fpga-tools'\n",
    "\n",
    "commands = list()\n",
    "commands.append(f'[ ! -d {tools_location} ] && mkdir -p {tools_location}')\n",
    "commands.append(f'curl -k -u {nginx_user}:{nginx_password} https://resources.fabric-testbed.net/fpga-tools/{configdpdk_script}  > {tools_location}/{os.path.basename(configdpdk_script)}')\n",
    "commands.append(f'chmod +x {tools_location}/{os.path.basename(configdpdk_script)}')\n",
    "\n",
    "for command in commands:\n",
    "   print(f'--- Node {node_name}: Executing command: {command}')\n",
    "   stdout, stderr = node.execute(command)\n",
    "print('--- Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.4 Clone open-nic-driver repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkout the repo - open-nic-driver\n",
    "opennicdriver_repo = 'https://github.com/Xilinx/open-nic-driver.git'\n",
    "\n",
    "commands = list()\n",
    "commands.append(f'[ ! -d ~/fpga-tools ] && mkdir -p fpga-tools')\n",
    "commands.append(f'cd fpga-tools && git clone {opennicdriver_repo}')\n",
    "\n",
    "for command in commands:\n",
    "   print(f'--- Node {node_name}: Executing command: {command}')\n",
    "   stdout, stderr = node.execute(command)\n",
    "print('--- Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 4.1.5 Next transfer the Xilinx Vivado Lab package from the Storage VM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "tools_location = '~/xilinx-labtools/vivado-installer'\n",
    "\n",
    "commands = [f'[ ! -d {tools_location} ] && mkdir -p {tools_location}',\n",
    "            f'curl -k -u {nginx_user}:{nginx_password} https://resources.fabric-testbed.net/fpga-tools/{labtools_package}  > {tools_location}/{os.path.basename(labtools_package)}']\n",
    "\n",
    "for command in commands:\n",
    "   print(f'--- Node {node_name}: Executing command: {command}')\n",
    "   stdout, stderr = node.execute(command)\n",
    "print('--- Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 4.1.6 Next transfer the artifact from Storage VM into a folder in this repo. \n",
    "This file will be called `<application_name>.mcs` and should be placed in the `~/bitfile` directory before starting the firmware build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitfile_location = '~/fpga-bitfile'\n",
    "\n",
    "commands = [f'[ ! -d {bitfile_location} ] && mkdir -p {bitfile_location}',\n",
    "            f'curl -k -u {nginx_user}:{nginx_password} https://resources.fabric-testbed.net/fpga-tools/artifacts/{artifact_owner_username}/{artifact_version}/{artifact}  > {bitfile_location}/{artifact}',\n",
    "            f'curl -k -u {nginx_user}:{nginx_password} https://resources.fabric-testbed.net/fpga-tools/xrt/{artifact_golden}  > {bitfile_location}/{artifact_golden}']\n",
    "\n",
    "\n",
    "for command in commands:\n",
    "   print(f'--- Node {node_name}: Executing command: {command}')\n",
    "   stdout, stderr = node.execute(command)\n",
    "print('--- Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.2 Install - Vivado Lab Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Extract and install Xilinx Vivado Lab package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parse package name to get version\n",
    "import re\n",
    "\n",
    "pattern = re.compile('(Xilinx_)?Vivado_Lab_Lin_([\\d]{4}.[\\d]_[\\d]{4}_[\\d]{4}).tar.gz')\n",
    "m = pattern.match(os.path.basename(labtools_package))\n",
    "if m:\n",
    "    version = m[2]\n",
    "else:\n",
    "    version = 'Unknown'\n",
    "\n",
    "\n",
    "vivado_install_dir = \"/tools/Xilinx\"\n",
    " \n",
    "commands = list()\n",
    "commands.append(f'tar xf {tools_location}/{os.path.basename(labtools_package)} -C {tools_location}')\n",
    "commands.append(f'sudo {tools_location}/Vivado_Lab_Lin_{version}/xsetup --agree 3rdPartyEULA,XilinxEULA --batch Install --edition \"Vivado Lab Edition (Standalone)\" --location {vivado_install_dir}')\n",
    "\n",
    "\n",
    "for command in commands:\n",
    "   print(f'--- Node {node_name}: Executing command: {command}')\n",
    "   stdout, stderr = node.execute(command)\n",
    "print('--- Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 4.2.2 Install necessary libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = list()\n",
    "commands.append(f'sudo apt install -y lsb &> /tmp/fpga-apt-install.out')\n",
    "commands.append(f'sudo {tools_location}/Vivado_Lab_Lin_{version}/installLibs.sh &> /tmp/fpga-installLibs.out')\n",
    "\n",
    "for command in commands:\n",
    "   print(f'--- Node {node_name}: Executing command: {command}')\n",
    "   stdout, stderr = node.execute(command)\n",
    "print('--- Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 4.2.3 Install JTAG drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pattern = re.compile('([\\d]{4}.[\\d])_([\\d]{4}_[\\d]{4})')\n",
    "m = pattern.match(os.path.basename(version))\n",
    "if m:\n",
    "    version_major = m[1]\n",
    "else:\n",
    "    version_major = 'Unknown'\n",
    "\n",
    "\n",
    "commands = list()\n",
    "commands.append(f'sudo {vivado_install_dir}/Vivado_Lab/{version_major}/data/xicom/cable_drivers/lin64/install_script/install_drivers/install_drivers')\n",
    "\n",
    "for command in commands:\n",
    "   print(f'--- Node {node_name}: Executing command: {command}')\n",
    "   stdout, stderr = node.execute(command)\n",
    "print('--- Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.4 Update packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = list()\n",
    "commands.append(f'(sudo apt -y update && sudo apt -y upgrade) &> /tmp/fpga-apt-upgrade.log')\n",
    "\n",
    "for command in commands:\n",
    "   print(f'--- Node {node_name}: Executing command: {command}')\n",
    "   stdout, stderr = node.execute(command)\n",
    "print('--- Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 4.2.5 Reboot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reboot = 'sudo reboot'\n",
    "try:\n",
    "    print(reboot)\n",
    "    node.execute(reboot)\n",
    "    \n",
    "    slice.wait_ssh(timeout=360,interval=10,progress=True)\n",
    "\n",
    "    print(\"Now testing SSH abilites to reconnect...\",end=\"\")\n",
    "    slice.update()\n",
    "    slice.test_ssh()\n",
    "    print(\"Reconnected!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Fail: {e}\")  \n",
    "\n",
    "node.config()\n",
    "print(\"Done\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.6 Get the JTAG ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = list()\n",
    "commands.append(f'source {vivado_install_dir}/Vivado_Lab/{version_major}/settings64.sh && vivado_lab -mode batch -source ~/fpga-tools/P4OpenNIC_Public/FABRIC-P4/scripts/get_jtag.tcl | grep -o \"Xilinx/[^[:space:]]*\" | cut -d/ -f2 > /tmp/fpga-jtag.id')\n",
    "commands.append(f'echo {fpga_bdf} > /tmp/fpga-bdf.id')\n",
    "\n",
    "for command in commands:\n",
    "   print(f'--- Node {node_name}: Executing command: {command}')\n",
    "   stdout, stderr = node.execute(command)\n",
    "print('--- Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.7 Install kernel-headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = list()\n",
    "commands.append(f'sudo apt install -y linux-headers-$(uname -r) &> /tmp/fpga-apt-kernel-headers.log')\n",
    "\n",
    "for command in commands:\n",
    "   print(f'--- Node {node_name}: Executing command: {command}')\n",
    "   stdout, stderr = node.execute(command)\n",
    "print('--- Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.8 Install libraries for running Vivado GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = list()\n",
    "commands.append(f'sudo apt-get install -y libxrender1 libxtst6 libxi6 &> /tmp/fpga-apt-libs.log')\n",
    "\n",
    "for command in commands:\n",
    "   print(f'--- Node {node_name}: Executing command: {command}')\n",
    "   stdout, stderr = node.execute(command)\n",
    "print('--- Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Install - Alveo Packages\n",
    "https://www.xilinx.com/support/download/index.html/content/xilinx/en/downloadNav/alveo/u280.html\n",
    "\n",
    "1. Xilinx Runtime\n",
    "\n",
    "   The Xilinx runtime (XRT) is a low level communication layer (APIs and drivers) between the host and the card.\n",
    "   - [xrt_202320.2.16.204_20.04-amd64-xrt.deb](https://www.xilinx.com/bin/public/openDownload?filename=xrt_202320.2.16.204_20.04-amd64-xrt.deb)\n",
    "\n",
    " \n",
    "2. Deployment Target Platform\n",
    "\n",
    "   The deployment target platform is the communication layer physically implemented and flashed into the card.\n",
    "   - [xilinx-u280-gen3x16-xdma_2023.2_2023_1014_0238-all.deb.tar.gz](https://www.xilinx.com/bin/public/openDownload?filename=xilinx-u280-gen3x16-xdma_2023.2_2023_1014_0238-all.deb.tar.gz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This scheme is taking long to download the packages from the repos.\n",
    "# Use the following scheme\n",
    "\n",
    "###commands = list()\n",
    "###commands.append(f'sudo wget -qO - https://www.xilinx.com/support/download/2020-2/xilinx-master-signing-key.asc | sudo apt-key add -')\n",
    "###commands.append(f'echo \"deb https://packages.xilinx.com/artifactory/debian-packages $(lsb_release -cs) main\" | sudo tee -a /etc/apt/sources.list.d/xlnx.list')\n",
    "###commands.append(f'(sudo apt-get update && sudo apt-get install -y xilinx-u280-gen3x16-xdma-base=1-3585717 xilinx-u280-gen3x16-xdma-validate=1-3585755 xilinx-cmc-u280=1.3.5-3592445 xilinx-sc-fw-u280=4.3.28-1.ea1b92f ) &> /tmp/fpga-apt-alveo.log')\n",
    "\n",
    "###for command in commands:\n",
    "###   print(f'--- Node {node_name}: Executing command: {command}')\n",
    "###   stdout, stderr = node.execute(command)\n",
    "###print('--- Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xbflash2 and Xilinx Runtime Target Platform - Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "tools_location = '~/xilinx-labtools/alveo-packages'\n",
    "\n",
    "commands = list()\n",
    "commands.append(f'[ ! -d {tools_location} ] && mkdir -p {tools_location}')\n",
    "###commands.append(f'wget -q https://www.xilinx.com/bin/public/openDownload?filename=xrt_202210.2.13.466_20.04-amd64-xbflash2.deb -O {tools_location}/xrt_202210.2.13.466_20.04-amd64-xbflash2.deb')\n",
    "commands.append(f'curl -k -u {nginx_user}:{nginx_password} https://resources.fabric-testbed.net/fpga-tools/{xbflash2_package}  > {tools_location}/{os.path.basename(xbflash2_package)}')\n",
    "commands.append(f'curl -k -u {nginx_user}:{nginx_password} https://resources.fabric-testbed.net/fpga-tools/{xrt_package}  > {tools_location}/{os.path.basename(xrt_package)}')\n",
    "commands.append(f'curl -k -u {nginx_user}:{nginx_password} https://resources.fabric-testbed.net/fpga-tools/{deployment_tgt_package}  > {tools_location}/{os.path.basename(deployment_tgt_package)}')\n",
    "\n",
    "for command in commands:\n",
    "   print(f'--- Node {node_name}: Executing command: {command}')\n",
    "   stdout, stderr = node.execute(command)\n",
    "print('--- Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xbflash2 and Xilinx Runtime Target Platform - Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "tools_location = '~/xilinx-labtools/alveo-packages'\n",
    "\n",
    "commands = list()\n",
    "commands.append(f'[ ! -d {tools_location} ] && mkdir -p {tools_location}')\n",
    "\n",
    "commands.append(f'sudo apt-get install -y {tools_location}/xrt_202210.2.13.466_20.04-amd64-xbflash2.deb &> /tmp/fpga-apt-xbflash2.log')\n",
    "commands.append(f'sudo mkdir {tools_location}/xrt_platform')\n",
    "commands.append(f'sudo tar -zxvf {tools_location}/{os.path.basename(deployment_tgt_package)} -C {tools_location}/xrt_platform')\n",
    "commands.append(f'cd {tools_location}/xrt_platform && sudo apt-get install -y ./*.deb &> /tmp/fpga-apt-alveo.log')\n",
    "\n",
    "\n",
    "for command in commands:\n",
    "   print(f'--- Node {node_name}: Executing command: {command}')\n",
    "   stdout, stderr = node.execute(command)\n",
    "print('--- Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Flash the card \n",
    "\n",
    "This section includes 2 methods using Vivado Labtools - via CLI and GUI. Also a third method with xbflash2 is added.\n",
    "\n",
    "Use Method-1 or Method-2 or Method-3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1 - Flash the card via CLI\n",
    "\n",
    "Summary:\n",
    "- program_flash.tcl is customized to boot the FPGA from the configuration memory device as the last step. \n",
    "- Cold-rebooting of the server is not needed. \n",
    "- On the server, PCI bus is rescanned - see https://fabric-testbed.atlassian.net/browse/FIP-1528"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the block below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = list()\n",
    "commands.append(f'source {vivado_install_dir}/Vivado_Lab/{version_major}/settings64.sh && export JTAG_ID=`cat /tmp/fpga-jtag.id` && export EXTENDED_DEVICE_BDF1=`cat /tmp/fpga-bdf.id` && cd ~/fpga-tools/P4OpenNIC_Public/FABRIC-P4/scripts && pwd && echo $JTAG_ID && ./program_flash.sh {bitfile_location}/{artifact} au280 $JTAG_ID')\n",
    "\n",
    "\n",
    "for command in commands:\n",
    "    print(f'Executing {command}')\n",
    "    stdout, stderr = node.execute(command)\n",
    "\n",
    "print('Done')    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCI Rescan \n",
    "Initiate a PCI device rescan by first removing the FPGA devices, followed by triggering a PCI rescan.\n",
    "\n",
    "The following commands are executed on the user's behalf:\n",
    "```\n",
    "/opt/mlnx-scripts/pcie_disable_fatal.sh 25:00.0\n",
    "/opt/mlnx-scripts/pcie_disable_fatal.sh 25:00.1\n",
    "echo 1 > /sys/bus/pci/devices/0000:25:00.0/remove\n",
    "echo 1 > /sys/bus/pci/devices/0000:25:00.1/remove\n",
    "echo 1 > /sys/bus/pci/rescan\n",
    "```\n",
    "\n",
    "To verify that the FPGA devices remain accessible, list the PCI devices on the node both before and after the rescan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List PCI devices\n",
    "stdout, stderr = node.execute(\"lspci\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescan PCI devices\n",
    "node.rescan_pci(component_name=\"fpga1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List PCI devices\n",
    "stdout, stderr = node.execute(\"lspci\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>STOP - This is the end of flashing with Method-1</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2 - Flash the card Use Vivado Hardware Manager and boot from configuration memory device\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1 - Open Vivado\n",
    "\n",
    "Login to the VM\n",
    "```\n",
    "ssh -X -F ~/.ssh/<ssh_client_config> -i ~/.ssh/<sliver_key> ubuntu@<IP-address>\n",
    "```\n",
    "\n",
    "On the VM, execute the following to open Vivado GUI:\n",
    "```\n",
    "export VitisNetP4_Option_VISIBLE=true\n",
    "source /tools/Xilinx/Vivado_Lab/2023.2/settings64.sh \n",
    "vivado_lab\n",
    "```\n",
    "\n",
    "Follow the steps on https://fabric-testbed.atlassian.net/browse/FIP-1528?focusedCommentId=21607\n",
    "\n",
    "1. Open Vivado > Quick Start > Open Hardware Manager\n",
    "\n",
    "![Configuration Memory Device 1](./vivado_labtools/vivado-1.png)\n",
    "\n",
    "2. Open target (see the green banner) and Auto Connect\n",
    "\n",
    "![Configuration Memory Device 2](./vivado_labtools/vivado-2.png)\n",
    "\n",
    "3. Add Configuration Memory Device\n",
    "\n",
    "![Configuration Memory Device 3](./vivado_labtools/vivado-3.png)\n",
    "\n",
    "4. Search: mt25qu01g-spi-x1_x2_x4 and select\n",
    "\n",
    "![Configuration Memory Device 4](./vivado_labtools/vivado-4.png)\n",
    "![Configuration Memory Device 5](./vivado_labtools/vivado-5.png)\n",
    "\n",
    "5. Program Configuration Memory Device:\n",
    "   - Select the bitstream and OK\n",
    "   - There will be 2 steps (Step 1, 2) in the process.\n",
    "   \n",
    "![Configuration Memory Device 6](./vivado_labtools/vivado-6.png)\n",
    "![Configuration Memory Device 7](./vivado_labtools/vivado-7.png)\n",
    "![Configuration Memory Device 8](./vivado_labtools/vivado-8.png)\n",
    "![Configuration Memory Device 9](./vivado_labtools/vivado-9.png)\n",
    "![Configuration Memory Device 10](./vivado_labtools/vivado-10.png)\n",
    "![Configuration Memory Device 11](./vivado_labtools/vivado-11.png)\n",
    "\n",
    "6. Boot from configuration memory device\n",
    "\n",
    "![Configuration Memory Device 12](./vivado_labtools/vivado-12.png)\n",
    "\n",
    "7. Exit Vivado\n",
    "\n",
    "![Configuration Memory Device 13](./vivado_labtools/vivado-13.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCI Rescan \n",
    "Initiate a PCI device rescan by first removing the FPGA devices, followed by triggering a PCI rescan.\n",
    "\n",
    "The following commands are executed on the user's behalf:\n",
    "```\n",
    "/opt/mlnx-scripts/pcie_disable_fatal.sh 25:00.0\n",
    "/opt/mlnx-scripts/pcie_disable_fatal.sh 25:00.1\n",
    "echo 1 > /sys/bus/pci/devices/0000:25:00.0/remove\n",
    "echo 1 > /sys/bus/pci/devices/0000:25:00.1/remove\n",
    "echo 1 > /sys/bus/pci/rescan\n",
    "```\n",
    "\n",
    "To verify that the FPGA devices remain accessible, list the PCI devices on the node both before and after the rescan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List PCI devices\n",
    "stdout, stderr = node.execute(\"lspci\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescan PCI devices\n",
    "node.rescan_pci(component_name=\"fpga1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List PCI devices\n",
    "stdout, stderr = node.execute(\"lspci\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>STOP - This is the end of flashing with Method-2</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3 - Flash the card with xbflash2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.1 - Flash with xbflash2\n",
    "\n",
    "xbflash2 - https://xilinx.github.io/XRT/master/html/xbflash2.html#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = list()\n",
    "commands.append(f\"yes | sudo xbflash2 program --spi --image {bitfile_location}/{artifact} -d {fpga_bdf.replace('0000:','')}\")\n",
    "#commands.append(f\"yes | sudo xbflash2 program --spi --image {bitfile_location}/{artifact_golden} -d {fpga_bdf.replace('0000:','')}\")\n",
    "\n",
    "\n",
    "for command in commands:\n",
    "    print(f'Executing {command}')\n",
    "    stdout, stderr = node.execute(command)\n",
    "\n",
    "print('Done')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCI Rescan \n",
    "Initiate a PCI device rescan by first removing the FPGA devices, followed by triggering a PCI rescan.\n",
    "\n",
    "The following commands are executed on the user's behalf:\n",
    "```\n",
    "/opt/mlnx-scripts/pcie_disable_fatal.sh 25:00.0\n",
    "/opt/mlnx-scripts/pcie_disable_fatal.sh 25:00.1\n",
    "echo 1 > /sys/bus/pci/devices/0000:25:00.0/remove\n",
    "echo 1 > /sys/bus/pci/devices/0000:25:00.1/remove\n",
    "echo 1 > /sys/bus/pci/rescan\n",
    "```\n",
    "\n",
    "To verify that the FPGA devices remain accessible, list the PCI devices on the node both before and after the rescan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List PCI devices\n",
    "stdout, stderr = node.execute(\"lspci\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescan PCI devices\n",
    "node.rescan_pci(component_name=\"fpga1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List PCI devices\n",
    "stdout, stderr = node.execute(\"lspci\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>STOP - This is the end of flashing with Method-3</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 - Status and kernel drivers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 - Use configDPDK to read the registers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_location = '~/fpga-tools'\n",
    "\n",
    "commands = list()\n",
    "commands.append(f'cd {tools_location}/pcimem; make; [ ! -e {tools_location}/pcimem/configDPDK.sh ] && ln -s {tools_location}/configDPDK.sh')\n",
    "commands.append(f'cd {tools_location}/pcimem && ./configDPDK.sh')\n",
    "\n",
    "for command in commands:\n",
    "   print(f'--- Node {node_name}: Executing command: {command}')\n",
    "   stdout, stderr = node.execute(command)\n",
    "print('--- Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 - Install kernel module open-nic-driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_location = '~/fpga-tools'\n",
    "\n",
    "commands = list()\n",
    "commands.append(f'cd {tools_location}/open-nic-driver; make')\n",
    "commands.append(f'sudo rmmod onic &> /dev/null')\n",
    "commands.append(f'cd {tools_location}/open-nic-driver; sudo insmod onic.ko RS_FEC_ENABLED=0')\n",
    "commands.append(f'lsmod | grep onic')\n",
    "\n",
    "for command in commands:\n",
    "   print(f'--- Node {node_name}: Executing command: {command}')\n",
    "   stdout, stderr = node.execute(command)\n",
    "print('--- Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the process completes, shutoff the VM and __cold-reboot__ the worker node if you flashed persistent flash or __warm-reboot__ if flashing was into RAM. For the __cold-reboot__ case, it is more straightforward to delete the slice (Step 7), cold-reboot the worker node and re-create a slice with the flashed FPGA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Extend Slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get slice details and extend the slice. This cell is optional and can be executed as-needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = fablib.get_slice(name=slice_name)\n",
    "slice.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renew by 14 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "from datetime import timedelta\n",
    "\n",
    "# Set end host to now plus 14 days\n",
    "end_date = (datetime.now(timezone.utc) + timedelta(days=14)).strftime(\"%Y-%m-%d %H:%M:%S %z\")\n",
    "\n",
    "try:\n",
    "    slice = fablib.get_slice(name=slice_name)\n",
    "\n",
    "    slice.renew(end_date)\n",
    "except Exception as e:\n",
    "    print(f\"Exception: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Delete the slice\n",
    "\n",
    "Delete the slice after completing the programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    slice = fablib.get_slice(name=slice_name)\n",
    "    slice.delete()\n",
    "except Exception as e:\n",
    "    print(f\"Exception: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

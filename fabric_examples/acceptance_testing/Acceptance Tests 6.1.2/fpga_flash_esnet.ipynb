{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Functional Test 6.1.2 - Flash ESnet code into an FPGA persistent flash or RAM and validate\n",
    "\n",
    "This Jupyter notebook will allow you to flash experimenter FPGA code based on [ONS shell](https://github.com/Xilinx/open-nic-shell) into the FPGA persistent flash or RAM. If the persistent flash is used, the end result is an FPGA that even after a cold reboot of the server retains its programming with a standard Xilinx XRT shell. If the program is flashed into RAM, a warm reboot of the server will activate it. \n",
    "\n",
    "This procedure can be used to reset the FPGA at a given site after experiments or initialize a newly installed device. It generally follows the procedures described by [ESnet](https://github.com/esnet/esnet-smartnic-fw/blob/main/sn-stack/README.INSTALL.md#running-the-firmware) for U280 devices.\n",
    "\n",
    "It is assumed you are operating as part of the FABRIC Maintenance project and have access to the persistent volume named `fpga-tools` created on EDC where releavent tools are downloaded.\n",
    "\n",
    "This notebook is broken up into steps and does not have to be executed in sequence.\n",
    "\n",
    "- Step 2 Has multiple cells that initialize fablib and variables and creates a new slice\n",
    "  - The cells initializing the state __must always be executed__.\n",
    "  - Creating a slice is optional and can be skipped if slice already exists\n",
    "- Step 3 is a re-entrant cell and can be used any time you want to refresh information about the existing slice\n",
    "- Step 4 builds 3 docker images and saves them to Storage VM:\n",
    "  - Xilinx Labtools\n",
    "  - DPDK\n",
    "  - esnet-smartnic-fw based on experimenter-provided bitfile artifact\n",
    "  - Only the last one needs to be rebuilt often (for each user) the rest are already saved on the storage VM\n",
    "- Step 5 retrieves existing docker images built in Step 4 at a prior time. This is useful if you are reflashing multiple FPGAs with the same code - you can execute Step 5 once and the skip it for all further VMs simply retrieving the artifacts from Storage VM in this step\n",
    "- Step 6 can be done after Step 5 or Step 6 - that's the actual flashing and it involves identifying and rebooting the underlying server.\n",
    "- Step 7 is an optional 'extend the slice' step that can be excuted if Steps 2 and 3 have been executed.\n",
    "- Step 8 is 'delete the slice' that can be executed any time after Steps 2 and 3 have been executed.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Re-create a VM attached to fpga-tools volume on EDC\n",
    "\n",
    "In order to have access to necessary tools execute the notebook to [re-create a Storage VM attached](../../fablib_api/fabric_fpgas/fpga_tools_storage.ipynb) to the `fpga-tools` persistent storage. You must execute it as a member of FABRIC Staff project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Identify and isolate the worker node\n",
    "\n",
    "Unless the whole site is already in maintenance, using administrator tools identify the worker node with FPGA and put it in maintenance making sure it does not have experimenter VMs on it. You can check the [aggregate ads in JSON](https://github.com/fabric-testbed/aggregate-ads/tree/main/JSON) to make sure you are targeting the right worker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 2: Provision a VM on the desired worker with attached FPGA and FABNetv4 connection\n",
    "\n",
    "Create a slice with a VM attached to the FPGA on the desired site and a FABNetv4 interface to reach the Storage VM in Step 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize fablib and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize FABlib\n",
    "\n",
    "from fabrictestbed_extensions.fablib.fablib import FablibManager as fablib_manager\n",
    "\n",
    "fablib = fablib_manager()\n",
    "                     \n",
    "fablib.show_config();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define slice parameters - re-execute as needed to run any of the steps in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user artifact should be deposited Storage VM into /mnt/fpga_tools/static/artifacts/<owner username>/<version> since names of artifacts may be similar or same.\n",
    "artifact_owner_username = 'msada'\n",
    "artifact_version = 'v2'\n",
    "\n",
    "# edit the name of the user-provided artifact and labtools and DPDK docker images stored in Storage VM as needed\n",
    "artifact = 'artifacts.au280.p4_only.0.zip'\n",
    "dpdk_image = 'smartnic-dpdk-docker.tar.gz'\n",
    "labtools_image = 'xilinx-labtools-docker-2023.2_1013_2256.tar.gz'\n",
    "\n",
    "# the image built from artifact usually has the same name regardless of the artifact\n",
    "artifact_image = 'esnet-smartnic-fw.tar.gz'\n",
    "sn_stack_tar = 'sn-stack.tar.gz'\n",
    "\n",
    "# Xilins labtools package in Storage VM\n",
    "labtools_package = 'Vivado/Vivado_Lab_Lin_2023.2_1013_2256.tar.gz'\n",
    "sc_package = 'sc-fw-downloads/loadsc_v2.3.zip'\n",
    "sc_fw_package = 'sc-fw-downloads/SC_U280_4_3_31.zip'\n",
    "\n",
    "# setup site name\n",
    "site='CLEM'\n",
    "node_name='fpga-node'\n",
    "\n",
    "# FABNetv4 of storage VM - consult the Storage VM slice for this FABNetv4 IP address\n",
    "storage_vm_ip = \"10.132.129.2\"\n",
    "# username and password used in storage VM\n",
    "nginx_user = \"fpga_tools\"\n",
    "nginx_password = \"secret-password\"\n",
    "\n",
    "#\n",
    "# should not need to edit below\n",
    "FPGA_CHOICE='FPGA_Xilinx_U280'\n",
    "\n",
    "# name the slice and the node \n",
    "slice_name=f'Persistent esnet-smartnic slice with {FPGA_CHOICE} on {site}'\n",
    "print(f'Will create slice \"{slice_name}\" with node \"{node_name}\"')\n",
    "\n",
    "# don't edit - convert from FPGA type to a resource column name\n",
    "# to use in filter lambda function below\n",
    "choice_to_column = {\n",
    "    \"FPGA_Xilinx_U280\": \"fpga_u280_available\",\n",
    "}\n",
    "\n",
    "column_name = choice_to_column.get(FPGA_CHOICE, \"Unknown\")\n",
    "\n",
    "#fablib.get_image_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new slice \n",
    "\n",
    "Create a slice with FPGA component on selected site and access to FABNetv4 network.\n",
    "\n",
    "__NOTE:__ It is important to use a Docker-enabled image so that Docker can properly build docker images on IPv6-enabled sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Slice. Note that by default submit() call will poll for 360 seconds every 10-20 seconds\n",
    "# waiting for slice to come up. Normal expected time is around 2 minutes. \n",
    "slice = fablib.new_slice(name=slice_name)\n",
    "image = 'docker_ubuntu_20'\n",
    "\n",
    "# Add node with a 200G drive and 8 of CPU cores using Ubuntu 20 image\n",
    "node = slice.add_node(name=node_name, site=site, cores=8, disk=200, image=image)\n",
    "node.add_component(model=FPGA_CHOICE, name='fpga1')\n",
    "# be sure to add FABNetv4 so we can communicate with the slice that has the tools\n",
    "node.add_fabnet()\n",
    "\n",
    "# use the postboot script from docker examples\n",
    "node.add_post_boot_upload_directory('../../fablib_api/docker_containers/node_tools','.')\n",
    "node.add_post_boot_execute('node_tools/enable_docker.sh {{ _self_.image }} ')\n",
    "node.add_post_boot_upload_directory('node_config','.')\n",
    "node.add_post_boot_execute(f'chmod a+x node_config/ipv6-and-docker-plugins.sh && node_config/ipv6-and-docker-plugins.sh')\n",
    "\n",
    "# Submit Slice Request\n",
    "slice.submit();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add storage VM into /etc/hosts for convenience. __Consult the storage slice for the FABNetv4 IPv4 address of that VM.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = fablib.get_slice(slice_name)\n",
    "node = slice.get_node(name=node_name)   \n",
    "\n",
    "commands = list()\n",
    "commands.append(f\"echo {storage_vm_ip} fpga-tools-host | sudo tee -a /etc/hosts\")\n",
    "commands.append(f\"echo 127.0.0.1 {node_name} | sudo tee -a /etc/hosts\")\n",
    "\n",
    "for command in commands:\n",
    "    stdout, stderr = node.execute(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Inspect the slice\n",
    "Note that nat64 configuration is done at boot time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = fablib.get_slice(slice_name)\n",
    "\n",
    "node = slice.get_node(name=node_name)              \n",
    "\n",
    "node_addr = node.get_interface(network_name=f'FABNET_IPv4_{node.get_site()}').get_ip_addr()\n",
    "\n",
    "slice.show()\n",
    "slice.list_nodes()\n",
    "slice.list_networks()\n",
    "print(f'Node FABNetV4 IP Address is {node_addr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Build dockers\n",
    "\n",
    "In this step you can freshly build three docker images - Xilinx Linux Labtools, smartnic DPDK and smartnic-esnet-fw (this last one is based on the experimenter-provided artifact). Normally the labtools and dpdk should not be rebuilt even for each new artifact - they are static save for the possible changes in the way ESnet workflow works. \n",
    "\n",
    "The only artifact that needs to be regularly built is the one based on the user artifact. \n",
    "\n",
    "In each step docker images are produced and all are saved back to Storage VM for efficiency. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Xilinx Linux Labtools docker\n",
    "\n",
    "It is built once and stored on the storage VM. You should first skip to Step 6 and see if the image already exists. Only if it doesn't you can rebuild it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkout the repo\n",
    "tools_docker_repo = 'https://github.com/esnet/xilinx-labtools-docker.git'\n",
    "\n",
    "stdout, stderr = node.execute(f'git clone {tools_docker_repo}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch the Linux tools from Xilinx and place into appropriate location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "tools_location = '~/xilinx-labtools-docker/vivado-installer'\n",
    "sc_location = '~/xilinx-labtools-docker/sc-fw-downloads'\n",
    "\n",
    "commands = [f'mkdir -p {tools_location} {sc_location}',\n",
    "            f'curl -k -u {nginx_user}:{nginx_password} https://fpga-tools-host/fpga-tools/{labtools_package}  > {tools_location}/{os.path.basename(labtools_package)}',\n",
    "            f'curl -k -u {nginx_user}:{nginx_password} https://fpga-tools-host/fpga-tools/{sc_package} > {sc_location}/{os.path.basename(sc_package)}',\n",
    "            f'curl -k -u {nginx_user}:{nginx_password} https://fpga-tools-host/fpga-tools/{sc_fw_package} > {sc_location}/{os.path.basename(sc_fw_package)}']\n",
    "\n",
    "for command in commands:\n",
    "    print(f'Executing {command}')\n",
    "    stdout, stderr = node.execute(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the Xilinx tools docker.\n",
    "\n",
    "__NOTE:__ this takes a long time and produces a large Docker image with all logs going to `labtools_docker_build.log` in the notebook directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = 'cd ~/xilinx-labtools-docker/ && docker build --pull -t xilinx-labtools-docker:${USER}-dev . && docker image ls'\n",
    "\n",
    "print('For the log of the build check labtools_docker_build.log file in the notebook folder')\n",
    "\n",
    "# this will produce a huge amount of output, so best not to log it to the notebook, but to a file\n",
    "node_thread = node.execute_thread(command, output_file='labtools_docker_build.log')\n",
    "\n",
    "stdout, stderr = node_thread.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the docker image into a tar file, and compress it.\n",
    "__This takes a long time too__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse package name to get version\n",
    "import re\n",
    "\n",
    "pattern = re.compile('(Xilinx_)?Vivado_Lab_Lin_([\\d]{4}.[\\d]_[\\d]{4}_[\\d]{4}).tar.gz')\n",
    "m = pattern.match(os.path.basename(labtools_package))\n",
    "if m:\n",
    "    version = m[2]\n",
    "else:\n",
    "    version = 'Unknown'\n",
    "\n",
    "# save the image\n",
    "commands = list()\n",
    "commands.append(f'docker save -o xilinx-labtools-docker-{version}.tar xilinx-labtools-docker')\n",
    "commands.append(f'gzip -f9 xilinx-labtools-docker-{version}.tar')\n",
    "\n",
    "for command in commands:\n",
    "    print(f'Executing {command}')\n",
    "    stdout, stderr = node.execute(command)\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use WebDAV on Storage VM\n",
    "\n",
    "commands = list()\n",
    "commands.append(f\"curl -k -u {nginx_user}:{nginx_password} -T xilinx-labtools-docker-{version}.tar.gz https://fpga-tools-host/fpga-tools/smartnic-docker-images/\")\n",
    "\n",
    "for command in commands:\n",
    "    print(f'Executing {command}')\n",
    "    stdout, stderr = node.execute(command)\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building DPDK docker image\n",
    "\n",
    "This builds a DPDK docker image which normally should only be done once and stored on the Storage VM. You should first skip to Step 6 and see if the image already exists. Only if it doesn't you can rebuild it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkout the repo\n",
    "dpdk_docker_repo = 'https://github.com/esnet/smartnic-dpdk-docker.git'\n",
    "\n",
    "commands = list()\n",
    "commands.append(f'git clone {dpdk_docker_repo}')\n",
    "commands.append(f'cd smartnic-dpdk-docker && git submodule update --init --recursive')\n",
    "\n",
    "for command in commands:\n",
    "    print(f'Executing {command}')\n",
    "    stdout, stderr = node.execute(command)\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the container logging into `dpdk_docker_build.log` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = list()\n",
    "\n",
    "command = 'cd smartnic-dpdk-docker && docker build --pull -t smartnic-dpdk-docker:${USER}-dev .'\n",
    "\n",
    "# this will produce a huge amount of output, so best not to log it to the notebook, but to a file\n",
    "node_thread = node.execute_thread(command, output_file='dpdk_docker_build.log')\n",
    "\n",
    "stdout, stderr = node_thread.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the image to file, compress. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the image\n",
    "commands = list()\n",
    "commands.append(f'docker save -o smartnic-dpdk-docker.tar smartnic-dpdk-docker')\n",
    "commands.append(f'gzip -f9 smartnic-dpdk-docker.tar')\n",
    "\n",
    "for command in commands:\n",
    "    print(f'Executing {command}')\n",
    "    stdout, stderr = node.execute(command)\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ship it to storage VM assuming standard location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use WebDAV storage VM\n",
    "commands = list()\n",
    "commands.append(f\"curl -k -u {nginx_user}:{nginx_password} -T smartnic-dpdk-docker.tar.gz https://fpga-tools-host/fpga-tools/smartnic-docker-images/\")\n",
    "\n",
    "for command in commands:\n",
    "    print(f'Executing {command}')\n",
    "    stdout, stderr = node.execute(command)\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the firmware image using the hardware artifact provided by experimenter\n",
    "\n",
    "Here we build the firware image based on user-provided hardware artifact, following the process [here](https://github.com/esnet/esnet-smartnic-fw/tree/main). This generally needs to be done once for each version of the artifact provided by the experimenter. Then the same image can be reused on multiple sites. This section assumes you have already put the experimenter hardware artifact into Storage VM on `/mnt/fpga_tools/static/artifacts/<artifact owner username>/<artifact version>/`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkout the repo and submodules\n",
    "tools_docker_repo = 'https://github.com/esnet/esnet-smartnic-fw.git'\n",
    "\n",
    "commands = list()\n",
    "commands.append(f'git clone {tools_docker_repo}')\n",
    "commands.append(f'cd esnet-smartnic-fw && git checkout c064d4ac775ed1a4c50ec72dea3615f9c644433e && git submodule init && git submodule update')\n",
    "\n",
    "for command in commands:\n",
    "    print(f'Executing {command}')\n",
    "    stdout, stderr = node.execute(command)\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next transfer the artifact from Storage VM into a folder in this repo. This file will be called `artifacts.<board>.<app_name>.0.zip` and should be placed in the `sn-hw/` directory in git source tree before starting the firmware build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = list()\n",
    "\n",
    "commands.append(f'curl -k -u {nginx_user}:{nginx_password} https://fpga-tools-host/fpga-tools/artifacts/{artifact_owner_username}/{artifact_version}/{artifact}  > esnet-smartnic-fw/sn-hw/{artifact}')\n",
    "\n",
    "for command in commands:\n",
    "    print(f'Executing {command}')\n",
    "    stdout, stderr = node.execute(command)\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide the `.env` file to build, then build. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the artifact file is called artifacts.au280.p4_only.0.zip then it translates into\n",
    "# the following environment parameters\n",
    "env_file = \"\"\"\n",
    "SN_HW_VER=0\n",
    "SN_HW_BOARD=au280\n",
    "SN_HW_APP_NAME=p4_only\n",
    "\"\"\"\n",
    "\n",
    "# transfer the .env to the node\n",
    "command = f\"echo '{env_file}' | sudo tee ~/esnet-smartnic-fw/.env\"\n",
    "stdout, stderr = node.execute(command)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to build the docker with bitfiles (esnet-smartnic-fw). The log will go into `esnet-smartnic-fw-docker.log`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"cd esnet-smartnic-fw && ./build.sh\"\n",
    "\n",
    "# this will produce a huge amount of output, so best not to log it to the notebook, but to a file\n",
    "node_thread = node.execute_thread(command, output_file='esnet-smartnic-fw-docker.log')\n",
    "\n",
    "stdout, stderr = node_thread.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the image, compress. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the image\n",
    "commands = list()\n",
    "commands.append(f'docker save -o esnet-smartnic-fw.tar esnet-smartnic-fw')\n",
    "commands.append(f'gzip -f9 esnet-smartnic-fw.tar')\n",
    "\n",
    "for command in commands:\n",
    "    print(f'Executing {command}')\n",
    "    stdout, stderr = node.execute(command)\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update a .env file for deployment under `sn-stack/` folder. Note in FABRIC all FPGAs are currently __always__ listed under BDF `0000:00:1f` in the VM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = list()\n",
    "# append FPGA location to .env that should've been created by the build step\n",
    "commands.append(f'echo \"FPGA_PCIE_DEV=0000:00:1f\" >> esnet-smartnic-fw/sn-stack/.env')\n",
    "\n",
    "for command in commands:\n",
    "    print(f'Executing {command}')\n",
    "    stdout, stderr = node.execute(command)\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the `sn-stack/` folder with docker compose files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = list()\n",
    "\n",
    "commands.append(f'tar -zcf {sn_stack_tar} esnet-smartnic-fw/sn-stack/')\n",
    "\n",
    "for command in commands:\n",
    "    print(f'Executing {command}')\n",
    "    stdout, stderr = node.execute(command)\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ship the image to Storage VM along with meta-data directory that contains the docker compose files. __These are stored under /mnt/fpga_tools/static/artifacts/username/version/ - make sure this directory is world or nginx writable__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use WebDAV to move the docker image file into Storage VM into same folder where the artifact came from\n",
    "\n",
    "commands = list()\n",
    "commands.append(f\"curl -k -u {nginx_user}:{nginx_password} -T {artifact_image} https://fpga-tools-host/fpga-tools/artifacts/{artifact_owner_username}/{artifact_version}/\")\n",
    "commands.append(f\"curl -k -u {nginx_user}:{nginx_password} -T {sn_stack_tar} https://fpga-tools-host/fpga-tools/artifacts/{artifact_owner_username}/{artifact_version}/\")\n",
    "\n",
    "for command in commands:\n",
    "    print(f'Executing {command}')\n",
    "    stdout, stderr = node.execute(command)\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Retrieve docker images from Storage VM and install locally\n",
    "\n",
    "If you prebuilt the images and are just flashing a new FPGA, cells in this step will help you retrieve the previously built images from Storage VM and then install them into Docker on this VM.\n",
    "\n",
    "Most of the time you don't want to rebuild the DPDK and the Labtools images. You may need to build the image from user artifact, but if it is needed on multiple sites, it should be reused. You can select steps below as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve and install DPDK Docker image\n",
    "\n",
    "Retrieve previously built DPDK docker image and install it. Image names are set in the second cell of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the image and install it\n",
    "\n",
    "commands = list()\n",
    "commands.append(f'curl -k -u {nginx_user}:{nginx_password} https://fpga-tools-host/fpga-tools/smartnic-docker-images/{dpdk_image}  > {dpdk_image}')\n",
    "commands.append(f'docker load < {dpdk_image}')\n",
    "\n",
    "for command in commands:\n",
    "    print(f'Executing {command}')\n",
    "    stdout, stderr = node.execute(command)\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve and install Xilinx Labtools docker image\n",
    "\n",
    "Retrieve previously built labtools docker image and install it. Image names are set in the second cell of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the image and install it\n",
    "\n",
    "commands = list()\n",
    "commands.append(f'curl -k -u {nginx_user}:{nginx_password} https://fpga-tools-host/fpga-tools/smartnic-docker-images/{labtools_image}  > {labtools_image}')\n",
    "commands.append(f'docker load < {labtools_image}')\n",
    "\n",
    "for command in commands:\n",
    "    print(f'Executing {command}')\n",
    "    stdout, stderr = node.execute(command)\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve and install firmware image built from experimenter artifact\n",
    "Retrieve previously built firmware image and install it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the image and install it\n",
    "\n",
    "commands = list()\n",
    "commands.append(f'curl -k -u {nginx_user}:{nginx_password} https://fpga-tools-host/fpga-tools/artifacts/{artifact_owner_username}/{artifact_version}/{artifact_image}  > {artifact_image}')\n",
    "commands.append(f'docker load < {artifact_image}')\n",
    "commands.append(f'curl -k -u {nginx_user}:{nginx_password} https://fpga-tools-host/fpga-tools/artifacts/{artifact_owner_username}/{artifact_version}/{sn_stack_tar}  > {sn_stack_tar}')\n",
    "commands.append(f'tar -zxf {sn_stack_tar}')\n",
    "\n",
    "for command in commands:\n",
    "    print(f'Executing {command}')\n",
    "    stdout, stderr = node.execute(command)\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check loaded docker images\n",
    "Prior to flashing/loading bitfile into RAM there should be three docker images which you either built directly or retrieved from Storage VM - __xilinx-labtools-docker, smartnic-dpdk-docker, and esnet-smartnic-fw__. They are always named this way so the docker compose in the flashing step can find them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = 'docker image ls'\n",
    "\n",
    "stdout, stderr = node.execute(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Flash the card (into persistent flash or RAM)\n",
    "\n",
    "Here we continue to follow the instructions [here](https://github.com/esnet/esnet-smartnic-fw/tree/main) and [here](https://github.com/esnet/esnet-smartnic-fw/blob/main/sn-stack/README.INSTALL.md#running-the-firmware).\n",
    "\n",
    "__Note:__ Prior to proceeding please be sure to follow these steps to open the iDrac interface of the server you are working on as it will need to be __cold rebooted__ (in the case of a persistent reflash) or __warm rebooted__ (in the case of a RAM reflash):\n",
    "\n",
    "1. Login to FABRIC VPN\n",
    "2. Login to the head node of the cluster on which this VM is created\n",
    "3. Login to the specific worker from the head node\n",
    "    - Use Step 3 of this notebook to locate the worker using `Host` column of the sliver table\n",
    "4. Run the following command to retrieve the asset tag: `cat /sys/class/dmi/id/chassis_serial` \n",
    "5. Login to the iDrac by using the [following formula](https://fabric-testbed.atlassian.net/wiki/spaces/FP/pages/1490812935/iDRAC+Setup): `192.168.<`[site index](https://fabric-testbed.atlassian.net/wiki/spaces/FP/pages/168624158/List+of+Hanks+FABRIC+Site+Information)`>.<100 + worker index>`.\n",
    "    - indi-w2.fabric-testbed.net -> 192.168.36.102 \n",
    "6. In the 'System Information' pane of iDrac compare the 'Service Tag' to the output of 4 above. This is to make sure we are rebooting the right server.\n",
    "\n",
    "Now we flash the card - write to __persistent flash__, which is generally what you want (takes 20 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = 'cd esnet-smartnic-fw/sn-stack/ && docker compose --profile smartnic-flash run --rm smartnic-flash-rescue && docker compose down -v --remove-orphans'\n",
    "\n",
    "stdout, stderr = node.execute(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Alternatively we flash the RAM__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = 'cd esnet-smartnic-fw/sn-stack/ && docker compose up'\n",
    "\n",
    "stdout, stderr = node.execute(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__PCI rescan can be carried out with new rescan_pci API__\n",
    "Please use the reboot option when this does not show the required number of PCI devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List PCI devices\n",
    "stdout, stderr = node.execute(\"lspci\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescan PCI devices\n",
    "node.rescan_pci(component_name=\"fpga1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List PCI devices\n",
    "stdout, stderr = node.execute(\"lspci\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the process completes, shutoff the VM and __cold-reboot__ the worker node if you flashed persistent flash or __warm-reboot__ if flashing was into RAM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = 'sudo /sbin/halt'\n",
    "\n",
    "stdout, stderr = node.execute(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use the iDrac console to perform a reboot (cold or warm)\n",
    "2. After the reboot completes delete the slice using Step 9\n",
    "3. Login to the worker node as root and validate that Xilinx programming has been activated. Generally you should see something like:\n",
    "```\n",
    "ubuntu@fpga-node:~$ lspci | grep Xilinx\n",
    "25:00.0 Network controller: Xilinx Corporation Device 903f\n",
    "25:00.1 Network controller: Xilinx Corporation Device 913f\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Check CMAC (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the steps in this section to check and verify CMAC/PHY status. \n",
    "These steps can be used after the server is cold-rebooted. \n",
    "1. Flash the FPGA, delete the slice.\n",
    "2. Cold-reboot the server.\n",
    "3. Create a new slice and follow Steps 1,2,3,5 (exclude Step 6 for flashing).\n",
    "4. Check CMAC status."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure environment for the profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = 'cd esnet-smartnic-fw/sn-stack/ && echo \"COMPOSE_PROFILES=smartnic-mgr-vfio-unlock\" >> .env && docker compose up -d'\n",
    "\n",
    "stdout, stderr = node.execute(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = 'cd esnet-smartnic-fw/sn-stack/ && docker compose ps -a'\n",
    "\n",
    "stdout, stderr = node.execute(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enable CMAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = 'cd esnet-smartnic-fw/sn-stack/ && docker compose exec smartnic-fw sn-cli cmac enable'\n",
    "\n",
    "stdout, stderr = node.execute(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check CMAC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = 'cd esnet-smartnic-fw/sn-stack/ && docker compose exec smartnic-fw sn-cli cmac status'\n",
    "\n",
    "stdout, stderr = node.execute(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference output is below. In case \"DOWN\" status is reported, first step is re-flashing the card, second step is checking the cables physically.\n",
    "```\n",
    "CMAC0\n",
    "  Tx (MAC Enabled/RS-FEC Off/PHY UP -> UP)  \n",
    "  Rx (MAC Enabled/RS-FEC Off/PHY UP -> UP)  \n",
    "\n",
    "CMAC1\n",
    "  Tx (MAC Enabled/RS-FEC Off/PHY UP -> UP)  \n",
    "  Rx (MAC Enabled/RS-FEC Off/PHY UP -> UP)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stop containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = 'cd esnet-smartnic-fw/sn-stack/ && docker compose down'\n",
    "\n",
    "stdout, stderr = node.execute(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Extend Slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get slice details and extend the slice. This cell is optional and can be executed as-needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = fablib.get_slice(name=slice_name)\n",
    "slice.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renew by 14 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "from datetime import timedelta\n",
    "\n",
    "# Set end host to now plus 14 days\n",
    "end_date = (datetime.now(timezone.utc) + timedelta(days=14)).strftime(\"%Y-%m-%d %H:%M:%S %z\")\n",
    "\n",
    "try:\n",
    "    slice = fablib.get_slice(name=slice_name)\n",
    "\n",
    "    slice.renew(end_date)\n",
    "except Exception as e:\n",
    "    print(f\"Exception: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Delete the slice\n",
    "\n",
    "Delete the slice after completing the programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = fablib.get_slice(name=slice_name)\n",
    "slice.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Functional Test 6.1.4 - Flash XDMA shell with FireSim code into an FPGA persistent flash or RAM and validate\n",
    "\n",
    "This Jupyter notebook will allow you to flash experimenter FPGA code based on [XDMA shell](https://docs.fires.im/en/stable/Getting-Started-Guides/On-Premises-FPGA-Getting-Started/Initial-Setup/Xilinx-Alveo-U280.html#install-your-fpga-s) into the FPGA persistent flash or RAM. If the persistent flash is used, the end result is an FPGA that even after a cold reboot of the server retains its programming with a standard [Xilinx XDMA shell](https://github.com/Xilinx/dma_ip_drivers/tree/master/XDMA). If the program is flashed into RAM, a warm reboot of the server will activate it. \n",
    "\n",
    "This procedure can be used to reset the FPGA at a given site after experiments or initialize a newly installed device. \n",
    "\n",
    "It is assumed you are operating as part of the FABRIC Maintenance project and have access to the persistent volume named `fpga-tools` created on EDC where releavent tools are downloaded.\n",
    "\n",
    "This notebook is broken up into steps and does not have to be executed in sequence.\n",
    "\n",
    "- Step 2 Has multiple cells that initialize fablib and variables and creates a new slice\n",
    "  - The cells initializing the state __must always be executed__.\n",
    "  - Creating a slice is optional and can be skipped if slice already exists\n",
    "- Step 3 is a re-entrant cell and can be used any time you want to refresh information about the existing slice\n",
    "- Step 4 fetches the tools from the Storage VM and installs:\n",
    "  - Xilinx Labtools\n",
    "  - experimenter-provided bitfile artifact\n",
    "- Step 5 is the actual flashing and it involves identifying and rebooting the underlying server.\n",
    "- Step 6 is an optional 'extend the slice' step that can be excuted if Steps 2 and 3 have been executed.\n",
    "- Step 7 is 'delete the slice' that can be executed any time after Steps 2 and 3 have been executed.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Re-create a VM attached to fpga-tools volume on EDC\n",
    "\n",
    "In order to have access to necessary tools execute the notebook to [re-create a Storage VM attached](../../fablib_api/fabric_fpgas/fpga_tools_storage.ipynb) to the `fpga-tools` persistent storage. You must execute it as a member of FABRIC Staff project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Identify and isolate the worker node\n",
    "\n",
    "Unless the whole site is already in maintenance, using administrator tools identify the worker node with FPGA and put it in maintenance making sure it does not have experimenter VMs on it. You can check the [aggregate ads in JSON](https://github.com/fabric-testbed/aggregate-ads/tree/main/JSON) to make sure you are targeting the right worker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 2: Provision a VM on the desired worker with attached FPGA and FABNetv4 connection\n",
    "\n",
    "Create a slice with a VM attached to the FPGA on the desired site and a FABNetv4 interface to reach the Storage VM in Step 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize fablib and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize FABlib\n",
    "\n",
    "from fabrictestbed_extensions.fablib.fablib import FablibManager as fablib_manager\n",
    "\n",
    "fablib = fablib_manager()\n",
    "                     \n",
    "fablib.show_config();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define slice parameters - re-execute as needed to run any of the steps in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user artifact should be deposited Storage VM into /mnt/fpga_tools/static/artifacts/<owner username>/<version> since names of artifacts may be similar or same.\n",
    "artifact_owner_username = 'xdma_firesim'\n",
    "artifact_version = 'v1'\n",
    "\n",
    "# edit the name of the user-provided artifact and labtools and DPDK docker images stored in Storage VM as needed\n",
    "\n",
    "artifact = 'firesim.mcs'\n",
    "artifact_golden = 'revert_to_golden.mcs'\n",
    "\n",
    "# Xilinx labtools package in Storage VM\n",
    "labtools_package = 'Vivado/Vivado_Lab_Lin_2023.2_1013_2256.tar.gz'\n",
    "\n",
    "# Xilinx xrt package in Storage VM\n",
    "xrt_package = 'alveo-packages/xrt_202320.2.16.204_20.04-amd64-xrt.deb'\n",
    "\n",
    "# Xilinx deployment target package in Storage VM\n",
    "deployment_tgt_package = 'alveo-packages/xilinx-u280-gen3x16-xdma_2023.2_2023_1014_0238-all.deb.tar.gz'\n",
    "\n",
    "# Xilinx xbflash2 package in Storage VM\n",
    "xbflash2_package = 'alveo-packages/xrt_202210.2.13.466_20.04-amd64-xbflash2.deb'\n",
    "\n",
    "# Pcimem configDPDK.sh script in Storage VM\n",
    "configdpdk_script = 'alveo-utilities/configDPDK.sh'\n",
    "\n",
    "# FABNetv4 of storage VM - consult the Storage VM slice for this FABNetv4 IP address\n",
    "storage_vm_ip = \"10.132.129.2\"\n",
    "# username and password used in storage VM\n",
    "nginx_user = \"fpga_tools\"\n",
    "nginx_password = \"secret-password\"\n",
    "\n",
    "#\n",
    "# should not need to edit below\n",
    "FPGA_CHOICE='FPGA_Xilinx_U280'\n",
    "\n",
    "\n",
    "# don't edit - convert from FPGA type to a resource column name\n",
    "# to use in filter lambda function below\n",
    "choice_to_column = {\n",
    "    \"FPGA_Xilinx_U280\": \"fpga_u280_available\",\n",
    "}\n",
    "\n",
    "column_name = choice_to_column.get(FPGA_CHOICE, \"Unknown\")\n",
    "\n",
    "fpga_bdf = \"0000:1f:00.0\"\n",
    "\n",
    "#fablib.get_image_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup site name\n",
    "site='RENC'\n",
    "node_name='fpga-node'\n",
    "\n",
    "# name the slice and the node \n",
    "slice_name=f'Persistent slice with {FPGA_CHOICE} on {site}'\n",
    "print(f'Will create slice \"{slice_name}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a new slice \n",
    "\n",
    "Create a slice with FPGA component on selected site and access to FABNetv4 network.\n",
    "\n",
    "__NOTE:__ It is important to use a Docker-enabled image so that Docker can properly build docker images on IPv6-enabled sites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Slice. Note that by default submit() call will poll for 360 seconds every 10-20 seconds\n",
    "# waiting for slice to come up. Normal expected time is around 2 minutes. \n",
    "slice = fablib.new_slice(name=slice_name)\n",
    "image = 'docker_ubuntu_20'\n",
    "\n",
    "# Add node with a 200G drive and 8 of CPU cores using Ubuntu 20 image\n",
    "node = slice.add_node(name=node_name, site=site, cores=8, disk=200, image=image)\n",
    "node.add_component(model=FPGA_CHOICE, name='fpga1')\n",
    "# be sure to add FABNetv4 so we can communicate with the slice that has the tools\n",
    "node.add_fabnet()\n",
    "\n",
    "# use the postboot script from docker examples\n",
    "node.add_post_boot_upload_directory('../../fablib_api/docker_containers/node_tools','.')\n",
    "node.add_post_boot_execute('node_tools/enable_docker.sh {{ _self_.image }} ')\n",
    "node.add_post_boot_upload_directory('node_config','.')\n",
    "node.add_post_boot_execute(f'chmod a+x node_config/ipv6-and-docker-plugins.sh && node_config/ipv6-and-docker-plugins.sh')\n",
    "\n",
    "# Submit Slice Request\n",
    "slice.submit();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add storage VM into /etc/hosts for convenience. __Consult the storage slice for the FABNetv4 IPv4 address of that VM.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = fablib.get_slice(slice_name)\n",
    "node = slice.get_node(name=node_name)   \n",
    "\n",
    "commands = list()\n",
    "commands.append(f\"echo {storage_vm_ip} fpga-tools-host | sudo tee -a /etc/hosts\")\n",
    "commands.append(f\"echo 127.0.0.1 {node_name} | sudo tee -a /etc/hosts\")\n",
    "\n",
    "for command in commands:\n",
    "    stdout, stderr = node.execute(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Inspect the slice\n",
    "Note that nat64 configuration is done at boot time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = fablib.get_slice(slice_name)\n",
    "\n",
    "node = slice.get_node(name=node_name)              \n",
    "\n",
    "node_addr = node.get_interface(network_name=f'FABNET_IPv4_{node.get_site()}').get_ip_addr()\n",
    "\n",
    "slice.show()\n",
    "slice.list_nodes()\n",
    "slice.list_networks()\n",
    "print(f'Node FABNetV4 IP Address is {node_addr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 4: Fetch Tools and Install Vivado Lab\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Fetch the Linux tools from Xilinx and place into appropriate location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 4.1.1 Clone OCT-FPGA repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkout the repo\n",
    "\n",
    "#\n",
    "# This repo is forked from https://github.com/OCT-FPGA/P4OpenNIC_Public.git\n",
    "# program_flash.tcl is modified to include commands for booting from the \n",
    "# configuration memory device\n",
    "#\n",
    "\n",
    "tools_neu_repo = 'https://github.com/mcevik0/P4OpenNIC_Public.git'\n",
    "\n",
    "commands = list()\n",
    "commands.append(f'[ ! -d ~/fpga-tools ] && mkdir -p ~/fpga-tools')\n",
    "commands.append(f'cd fpga-tools && git clone {tools_neu_repo} && cd P4OpenNIC_Public && git checkout fpga-flash-boot-from-config-mem')\n",
    "\n",
    "for command in commands:\n",
    "    print(f'Executing {command}')\n",
    "    stdout, stderr = node.execute(command)\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 4.1.2 Clone pcimem repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkout the repo\n",
    "\n",
    "# checkout the repo\n",
    "pcimem_repo = 'https://github.com/billfarrow/pcimem.git'\n",
    "\n",
    "commands = list()\n",
    "commands.append(f'[ ! -d ~/fpga-tools ] && mkdir -p fpga-tools')\n",
    "commands.append(f'cd fpga-tools && git clone {pcimem_repo}')\n",
    "\n",
    "for command in commands:\n",
    "    print(f'Executing {command}')\n",
    "    stdout, stderr = node.execute(command)\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.3 Copy configDPDK.sh from the Storage VM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "tools_location = '~/fpga-tools'\n",
    "\n",
    "commands = list()\n",
    "commands.append(f'[ ! -d {tools_location} ] && mkdir -p {tools_location}')\n",
    "commands.append(f'curl -k -u {nginx_user}:{nginx_password} https://fpga-tools-host/fpga-tools/{configdpdk_script}  > {tools_location}/{os.path.basename(configdpdk_script)}')\n",
    "commands.append(f'chmod +x {tools_location}/{os.path.basename(configdpdk_script)}')\n",
    "\n",
    "for command in commands:\n",
    "   print(f'--- Node {node_name}: Executing command: {command}')\n",
    "   stdout, stderr = node.execute(command)\n",
    "print('--- Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.4 Clone open-nic-driver repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkout the repo - open-nic-driver\n",
    "opennicdriver_repo = 'https://github.com/Xilinx/open-nic-driver.git'\n",
    "\n",
    "commands = list()\n",
    "commands.append(f'[ ! -d ~/fpga-tools ] && mkdir -p fpga-tools')\n",
    "commands.append(f'cd fpga-tools && git clone {opennicdriver_repo}')\n",
    "\n",
    "for command in commands:\n",
    "   print(f'--- Node {node_name}: Executing command: {command}')\n",
    "   stdout, stderr = node.execute(command)\n",
    "print('--- Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 4.1.5 Next transfer the Xilinx Vivado Lab package from the Storage VM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "tools_location = '~/xilinx-labtools/vivado-installer'\n",
    "\n",
    "commands = [f'[ ! -d {tools_location} ] && mkdir -p {tools_location}',\n",
    "            f'curl -k -u {nginx_user}:{nginx_password} https://fpga-tools-host/fpga-tools/{labtools_package}  > {tools_location}/{os.path.basename(labtools_package)}']\n",
    "\n",
    "for command in commands:\n",
    "   print(f'--- Node {node_name}: Executing command: {command}')\n",
    "   stdout, stderr = node.execute(command)\n",
    "print('--- Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 4.1.6 Next transfer the artifact from Storage VM into a folder in this repo. \n",
    "This file will be called `<application_name>.mcs` and should be placed in the `~/bitfile` directory before starting the firmware build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bitfile_location = '~/fpga-bitfile'\n",
    "\n",
    "commands = [f'[ ! -d {bitfile_location} ] && mkdir -p {bitfile_location}',\n",
    "            f'curl -k -u {nginx_user}:{nginx_password} https://fpga-tools-host/fpga-tools/artifacts/{artifact_owner_username}/{artifact_version}/{artifact}  > {bitfile_location}/{artifact}',\n",
    "            f'curl -k -u {nginx_user}:{nginx_password} https://fpga-tools-host/fpga-tools/xrt/{artifact_golden}  > {bitfile_location}/{artifact_golden}']\n",
    "\n",
    "\n",
    "for command in commands:\n",
    "   print(f'--- Node {node_name}: Executing command: {command}')\n",
    "   stdout, stderr = node.execute(command)\n",
    "print('--- Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4.2 Install - Vivado Lab Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Extract and install Xilinx Vivado Lab package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parse package name to get version\n",
    "import re\n",
    "\n",
    "pattern = re.compile('(Xilinx_)?Vivado_Lab_Lin_([\\d]{4}.[\\d]_[\\d]{4}_[\\d]{4}).tar.gz')\n",
    "m = pattern.match(os.path.basename(labtools_package))\n",
    "if m:\n",
    "    version = m[2]\n",
    "else:\n",
    "    version = 'Unknown'\n",
    "\n",
    "\n",
    "vivado_install_dir = \"/tools/Xilinx\"\n",
    " \n",
    "commands = list()\n",
    "commands.append(f'tar xf {tools_location}/{os.path.basename(labtools_package)} -C {tools_location}')\n",
    "commands.append(f'sudo {tools_location}/Vivado_Lab_Lin_{version}/xsetup --agree 3rdPartyEULA,XilinxEULA --batch Install --edition \"Vivado Lab Edition (Standalone)\" --location {vivado_install_dir}')\n",
    "\n",
    "\n",
    "for command in commands:\n",
    "   print(f'--- Node {node_name}: Executing command: {command}')\n",
    "   stdout, stderr = node.execute(command)\n",
    "print('--- Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 4.2.2 Install necessary libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = list()\n",
    "commands.append(f'sudo apt install -y lsb &> /tmp/fpga-apt-install.out')\n",
    "commands.append(f'sudo {tools_location}/Vivado_Lab_Lin_{version}/installLibs.sh &> /tmp/fpga-installLibs.out')\n",
    "\n",
    "for command in commands:\n",
    "   print(f'--- Node {node_name}: Executing command: {command}')\n",
    "   stdout, stderr = node.execute(command)\n",
    "print('--- Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 4.2.3 Install JTAG drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "pattern = re.compile('([\\d]{4}.[\\d])_([\\d]{4}_[\\d]{4})')\n",
    "m = pattern.match(os.path.basename(version))\n",
    "if m:\n",
    "    version_major = m[1]\n",
    "else:\n",
    "    version_major = 'Unknown'\n",
    "\n",
    "\n",
    "commands = list()\n",
    "commands.append(f'sudo {vivado_install_dir}/Vivado_Lab/{version_major}/data/xicom/cable_drivers/lin64/install_script/install_drivers/install_drivers')\n",
    "\n",
    "for command in commands:\n",
    "   print(f'--- Node {node_name}: Executing command: {command}')\n",
    "   stdout, stderr = node.execute(command)\n",
    "print('--- Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.4 Update packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = list()\n",
    "commands.append(f'(sudo apt -y update && sudo apt -y upgrade) &> /tmp/fpga-apt-upgrade.log')\n",
    "\n",
    "for command in commands:\n",
    "   print(f'--- Node {node_name}: Executing command: {command}')\n",
    "   stdout, stderr = node.execute(command)\n",
    "print('--- Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 4.2.5 Reboot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reboot = 'sudo reboot'\n",
    "try:\n",
    "    print(reboot)\n",
    "    node.execute(reboot)\n",
    "    \n",
    "    slice.wait_ssh(timeout=360,interval=10,progress=True)\n",
    "\n",
    "    print(\"Now testing SSH abilites to reconnect...\",end=\"\")\n",
    "    slice.update()\n",
    "    slice.test_ssh()\n",
    "    print(\"Reconnected!\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Fail: {e}\")  \n",
    "\n",
    "node.config()\n",
    "print(\"Done\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.6 Get the JTAG ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = list()\n",
    "commands.append(f'source {vivado_install_dir}/Vivado_Lab/{version_major}/settings64.sh && vivado_lab -mode batch -source ~/fpga-tools/P4OpenNIC_Public/FABRIC-P4/scripts/get_jtag.tcl | grep -o \"Xilinx/[^[:space:]]*\" | cut -d/ -f2 > /tmp/fpga-jtag.id')\n",
    "commands.append(f'echo {fpga_bdf} > /tmp/fpga-bdf.id')\n",
    "\n",
    "for command in commands:\n",
    "   print(f'--- Node {node_name}: Executing command: {command}')\n",
    "   stdout, stderr = node.execute(command)\n",
    "print('--- Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.7 Install kernel-headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = list()\n",
    "commands.append(f'sudo apt install -y linux-headers-$(uname -r) &> /tmp/fpga-apt-kernel-headers.log')\n",
    "\n",
    "for command in commands:\n",
    "   print(f'--- Node {node_name}: Executing command: {command}')\n",
    "   stdout, stderr = node.execute(command)\n",
    "print('--- Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.8 Install libraries for running Vivado GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = list()\n",
    "commands.append(f'sudo apt-get install -y libxrender1 libxtst6 libxi6 &> /tmp/fpga-apt-libs.log')\n",
    "\n",
    "for command in commands:\n",
    "   print(f'--- Node {node_name}: Executing command: {command}')\n",
    "   stdout, stderr = node.execute(command)\n",
    "print('--- Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Install - Alveo Packages\n",
    "https://www.xilinx.com/support/download/index.html/content/xilinx/en/downloadNav/alveo/u280.html\n",
    "\n",
    "1. Xilinx Runtime\n",
    "\n",
    "   The Xilinx runtime (XRT) is a low level communication layer (APIs and drivers) between the host and the card.\n",
    "   - [xrt_202320.2.16.204_20.04-amd64-xrt.deb](https://www.xilinx.com/bin/public/openDownload?filename=xrt_202320.2.16.204_20.04-amd64-xrt.deb)\n",
    "\n",
    " \n",
    "2. Deployment Target Platform\n",
    "\n",
    "   The deployment target platform is the communication layer physically implemented and flashed into the card.\n",
    "   - [xilinx-u280-gen3x16-xdma_2023.2_2023_1014_0238-all.deb.tar.gz](https://www.xilinx.com/bin/public/openDownload?filename=xilinx-u280-gen3x16-xdma_2023.2_2023_1014_0238-all.deb.tar.gz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This scheme is taking long to download the packages from the repos.\n",
    "# Use the following scheme\n",
    "\n",
    "###commands = list()\n",
    "###commands.append(f'sudo wget -qO - https://www.xilinx.com/support/download/2020-2/xilinx-master-signing-key.asc | sudo apt-key add -')\n",
    "###commands.append(f'echo \"deb https://packages.xilinx.com/artifactory/debian-packages $(lsb_release -cs) main\" | sudo tee -a /etc/apt/sources.list.d/xlnx.list')\n",
    "###commands.append(f'(sudo apt-get update && sudo apt-get install -y xilinx-u280-gen3x16-xdma-base=1-3585717 xilinx-u280-gen3x16-xdma-validate=1-3585755 xilinx-cmc-u280=1.3.5-3592445 xilinx-sc-fw-u280=4.3.28-1.ea1b92f ) &> /tmp/fpga-apt-alveo.log')\n",
    "\n",
    "###for command in commands:\n",
    "###   print(f'--- Node {node_name}: Executing command: {command}')\n",
    "###   stdout, stderr = node.execute(command)\n",
    "###print('--- Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xbflash2 and Xilinx Runtime Target Platform - Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "tools_location = '~/xilinx-labtools/alveo-packages'\n",
    "\n",
    "commands = list()\n",
    "commands.append(f'[ ! -d {tools_location} ] && mkdir -p {tools_location}')\n",
    "###commands.append(f'wget -q https://www.xilinx.com/bin/public/openDownload?filename=xrt_202210.2.13.466_20.04-amd64-xbflash2.deb -O {tools_location}/xrt_202210.2.13.466_20.04-amd64-xbflash2.deb')\n",
    "commands.append(f'curl -k -u {nginx_user}:{nginx_password} https://fpga-tools-host/fpga-tools/{xbflash2_package}  > {tools_location}/{os.path.basename(xbflash2_package)}')\n",
    "commands.append(f'curl -k -u {nginx_user}:{nginx_password} https://fpga-tools-host/fpga-tools/{xrt_package}  > {tools_location}/{os.path.basename(xrt_package)}')\n",
    "commands.append(f'curl -k -u {nginx_user}:{nginx_password} https://fpga-tools-host/fpga-tools/{deployment_tgt_package}  > {tools_location}/{os.path.basename(deployment_tgt_package)}')\n",
    "\n",
    "for command in commands:\n",
    "   print(f'--- Node {node_name}: Executing command: {command}')\n",
    "   stdout, stderr = node.execute(command)\n",
    "print('--- Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xbflash2 and Xilinx Runtime Target Platform - Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "tools_location = '~/xilinx-labtools/alveo-packages'\n",
    "\n",
    "commands = list()\n",
    "commands.append(f'[ ! -d {tools_location} ] && mkdir -p {tools_location}')\n",
    "\n",
    "commands.append(f'sudo apt-get install -y {tools_location}/xrt_202210.2.13.466_20.04-amd64-xbflash2.deb &> /tmp/fpga-apt-xbflash2.log')\n",
    "commands.append(f'sudo mkdir {tools_location}/xrt_platform')\n",
    "commands.append(f'sudo tar -zxvf {tools_location}/{os.path.basename(deployment_tgt_package)} -C {tools_location}/xrt_platform')\n",
    "commands.append(f'cd {tools_location}/xrt_platform && sudo apt-get install -y ./*.deb &> /tmp/fpga-apt-alveo.log')\n",
    "\n",
    "\n",
    "for command in commands:\n",
    "   print(f'--- Node {node_name}: Executing command: {command}')\n",
    "   stdout, stderr = node.execute(command)\n",
    "print('--- Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Flash the card \n",
    "\n",
    "This section includes 2 methods using Vivado Labtools - via CLI and GUI. Also a third method with xbflash2 is added.\n",
    "\n",
    "Use Method-1 or Method-2 or Method-3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1 - Flash the card via CLI\n",
    "\n",
    "Summary:\n",
    "- program_flash.tcl is customized to boot the FPGA from the configuration memory device as the last step. \n",
    "- Cold-rebooting of the server is not needed. \n",
    "- On the server, PCI bus is rescanned - see https://fabric-testbed.atlassian.net/browse/FIP-1528"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the block below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = list()\n",
    "commands.append(f'source {vivado_install_dir}/Vivado_Lab/{version_major}/settings64.sh && export JTAG_ID=`cat /tmp/fpga-jtag.id` && export EXTENDED_DEVICE_BDF1=`cat /tmp/fpga-bdf.id` && cd ~/fpga-tools/P4OpenNIC_Public/FABRIC-P4/scripts && pwd && echo $JTAG_ID && ./program_flash.sh {bitfile_location}/{artifact} au280 $JTAG_ID')\n",
    "\n",
    "\n",
    "for command in commands:\n",
    "    print(f'Executing {command}')\n",
    "    stdout, stderr = node.execute(command)\n",
    "\n",
    "print('Done')    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute PCIbus rescan on the worker node\n",
    "\n",
    "```\n",
    "/opt/mlnx-scripts/pcie_disable_fatal.sh 25:00.0\n",
    "/opt/mlnx-scripts//pcie_disable_fatal.sh 25:00.1\n",
    "echo 1 > /sys/bus/pci/devices/0000\\:25\\:00.0/remove\n",
    "echo 1 > /sys/bus/pci/devices/0000\\:25\\:00.1/remove\n",
    "echo 1 > /sys/bus/pci/rescan\n",
    "```\n",
    "\n",
    "#### <font color='red'>STOP - This is the end of flashing with Method-1</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2 - Flash the card Use Vivado Hardware Manager and boot from configuration memory device\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1 - Open Vivado\n",
    "\n",
    "Login to the VM\n",
    "```\n",
    "ssh -X -F ~/.ssh/<ssh_client_config> -i ~/.ssh/<sliver_key> ubuntu@<IP-address>\n",
    "```\n",
    "\n",
    "On the VM, execute the following to open Vivado GUI:\n",
    "```\n",
    "export VitisNetP4_Option_VISIBLE=true\n",
    "source /tools/Xilinx/Vivado_Lab/2023.2/settings64.sh \n",
    "vivado_lab\n",
    "```\n",
    "\n",
    "Follow the steps on https://fabric-testbed.atlassian.net/browse/FIP-1528?focusedCommentId=21607\n",
    "\n",
    "1. Open Vivado > Quick Start > Open Hardware Manager\n",
    "\n",
    "![Configuration Memory Device 1](./vivado_labtools/vivado-1.png)\n",
    "\n",
    "2. Open target (see the green banner) and Auto Connect\n",
    "\n",
    "![Configuration Memory Device 2](./vivado_labtools/vivado-2.png)\n",
    "\n",
    "3. Add Configuration Memory Device\n",
    "\n",
    "![Configuration Memory Device 3](./vivado_labtools/vivado-3.png)\n",
    "\n",
    "4. Search: mt25qu01g-spi-x1_x2_x4 and select\n",
    "\n",
    "![Configuration Memory Device 4](./vivado_labtools/vivado-4.png)\n",
    "![Configuration Memory Device 5](./vivado_labtools/vivado-5.png)\n",
    "\n",
    "5. Program Configuration Memory Device:\n",
    "   - Select the bitstream and OK\n",
    "   - Bitstream: <font color='red'>Use firesim.mcs</font>\n",
    "   - There will be 2 steps (Step 1, 2) in the process.\n",
    "   \n",
    "![Configuration Memory Device 6](./vivado_labtools/vivado-6.png)\n",
    "![Configuration Memory Device 7](./vivado_labtools/vivado-7.png)\n",
    "![Configuration Memory Device 8](./vivado_labtools/vivado-8.png)\n",
    "![Configuration Memory Device 9](./vivado_labtools/vivado-9.png)\n",
    "![Configuration Memory Device 10](./vivado_labtools/vivado-10.png)\n",
    "![Configuration Memory Device 11](./vivado_labtools/vivado-11.png)\n",
    "\n",
    "6. Boot from configuration memory device\n",
    "\n",
    "![Configuration Memory Device 12](./vivado_labtools/vivado-12.png)\n",
    "\n",
    "7. Exit Vivado\n",
    "\n",
    "![Configuration Memory Device 13](./vivado_labtools/vivado-13.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute PCIbus rescan on the worker node\n",
    "\n",
    "```\n",
    "/opt/mlnx-scripts/pcie_disable_fatal.sh 25:00.0\n",
    "/opt/mlnx-scripts//pcie_disable_fatal.sh 25:00.1\n",
    "echo 1 > /sys/bus/pci/devices/0000\\:25\\:00.0/remove\n",
    "echo 1 > /sys/bus/pci/devices/0000\\:25\\:00.1/remove\n",
    "echo 1 > /sys/bus/pci/rescan\n",
    "```\n",
    "\n",
    "#### <font color='red'>STOP - This is the end of flashing with Method-2</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescan the PCI bus (This section is not used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#commands = list()\n",
    "#commands.append(f'sudo bash -c \"echo 1 > /sys/bus/pci/devices/0000\\:1f\\:00.0/remove\"')\n",
    "#commands.append(f'sudo lspci -vd 10ee:')\n",
    "#commands.append(f'sudo bash -c \"echo 1 > /sys/bus/pci/rescan\"')\n",
    "#commands.append(f'sudo lspci -vd 10ee:')\n",
    "\n",
    "#for command in commands:\n",
    "#    print(f'Executing {command}')\n",
    "#    stdout, stderr = node.execute(command)\n",
    "\n",
    "#print('Done')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3 - Flash the card with xbflash2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.1 - Flash with xbflash2\n",
    "\n",
    "xbflash2 - https://xilinx.github.io/XRT/master/html/xbflash2.html#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "commands = list()\n",
    "commands.append(f\"yes | sudo xbflash2 program --spi --image {bitfile_location}/{artifact} -d {fpga_bdf.replace('0000:','')}\")\n",
    "#commands.append(f\"yes | sudo xbflash2 program --spi --image {bitfile_location}/{artifact_golden} -d {fpga_bdf.replace('0000:','')}\")\n",
    "\n",
    "\n",
    "for command in commands:\n",
    "    print(f'Executing {command}')\n",
    "    stdout, stderr = node.execute(command)\n",
    "\n",
    "print('Done')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute PCIbus rescan on the worker node\n",
    "\n",
    "```\n",
    "/opt/mlnx-scripts/pcie_disable_fatal.sh 25:00.0\n",
    "/opt/mlnx-scripts//pcie_disable_fatal.sh 25:00.1\n",
    "echo 1 > /sys/bus/pci/devices/0000\\:25\\:00.0/remove\n",
    "echo 1 > /sys/bus/pci/devices/0000\\:25\\:00.1/remove\n",
    "echo 1 > /sys/bus/pci/rescan\n",
    "```\n",
    "\n",
    "#### <font color='red'>STOP - This is the end of flashing with Method-3</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 - Status and kernel drivers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 - Use configDPDK to read the registers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_location = '~/fpga-tools'\n",
    "\n",
    "commands = list()\n",
    "commands.append(f'cd {tools_location}/pcimem; make; [ ! -e {tools_location}/pcimem/configDPDK.sh ] && ln -s {tools_location}/configDPDK.sh')\n",
    "commands.append(f'cd {tools_location}/pcimem && ./configDPDK.sh')\n",
    "\n",
    "for command in commands:\n",
    "   print(f'--- Node {node_name}: Executing command: {command}')\n",
    "   stdout, stderr = node.execute(command)\n",
    "print('--- Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 - Install kernel module open-nic-driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_location = '~/fpga-tools'\n",
    "\n",
    "commands = list()\n",
    "commands.append(f'cd {tools_location}/open-nic-driver; make')\n",
    "commands.append(f'sudo rmmod onic &> /dev/null')\n",
    "commands.append(f'cd {tools_location}/open-nic-driver; sudo insmod onic.ko RS_FEC_ENABLED=0')\n",
    "commands.append(f'lsmod | grep onic')\n",
    "\n",
    "for command in commands:\n",
    "   print(f'--- Node {node_name}: Executing command: {command}')\n",
    "   stdout, stderr = node.execute(command)\n",
    "print('--- Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the process completes, shutoff the VM and __cold-reboot__ the worker node if you flashed persistent flash or __warm-reboot__ if flashing was into RAM. For the __cold-reboot__ case, it is more straightforward to delete the slice (Step 7), cold-reboot the worker node and re-create a slice with the flashed FPGA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Extend Slice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get slice details and extend the slice. This cell is optional and can be executed as-needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = fablib.get_slice(name=slice_name)\n",
    "slice.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renew by 14 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from datetime import timezone\n",
    "from datetime import timedelta\n",
    "\n",
    "# Set end host to now plus 14 days\n",
    "end_date = (datetime.now(timezone.utc) + timedelta(days=14)).strftime(\"%Y-%m-%d %H:%M:%S %z\")\n",
    "\n",
    "try:\n",
    "    slice = fablib.get_slice(name=slice_name)\n",
    "\n",
    "    slice.renew(end_date)\n",
    "except Exception as e:\n",
    "    print(f\"Exception: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Delete the slice\n",
    "\n",
    "Delete the slice after completing the programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    slice = fablib.get_slice(name=slice_name)\n",
    "    slice.delete()\n",
    "except Exception as e:\n",
    "    print(f\"Exception: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

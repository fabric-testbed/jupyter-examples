{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using FABRIC GPUs\n",
    "\n",
    "Your compute nodes can include GPUs. These devices are made available as FABRIC components and can be added to your nodes like any other component.\n",
    "\n",
    "This example notebook will demonstrate how to reserve and use Nvidia GPU devices on FABRIC.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the Experiment\n",
    "\n",
    "#### Import FABRIC API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fabrictestbed_extensions.fablib.fablib import FablibManager as fablib_manager\n",
    "\n",
    "fablib = fablib_manager()\n",
    "                     \n",
    "fablib.show_config();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Node\n",
    "\n",
    "The cells below help you create a slice that contains a single node with an attached GPU. \n",
    "\n",
    "### Select GPU Type and select the FABRIC Site\n",
    "\n",
    "First decide on which GPU type you want to try - this will determine the subset of sites where your VM can be placed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick which GPU type we will use (execute this cell). \n",
    "\n",
    "# choices include\n",
    "# GPU_RTX6000\n",
    "# GPU_TeslaT4\n",
    "# GPU_A30\n",
    "# GPU_A40\n",
    "GPU_CHOICE = 'GPU_RTX6000' \n",
    "\n",
    "# don't edit - convert from GPU type to a resource column name\n",
    "# to use in filter lambda function below\n",
    "choice_to_column = {\n",
    "    \"GPU_RTX6000\": \"rtx6000_available\",\n",
    "    \"GPU_TeslaT4\": \"tesla_t4_available\",\n",
    "    \"GPU_A30\": \"a30_available\",\n",
    "    \"GPU_A40\": \"a40_available\"\n",
    "}\n",
    "\n",
    "column_name = choice_to_column.get(GPU_CHOICE, \"Unknown\")\n",
    "print(f'{column_name=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give the slice and the node in it meaningful names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name the slice and the node \n",
    "slice_name=f'My Simple GPU Slice with {GPU_CHOICE}'\n",
    "node_name='gpu-node'\n",
    "\n",
    "print(f'Will create slice \"{slice_name}\" with node \"{node_name}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a lambda filter to figure out which site the node will go to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a site with at least one available GPU of the selected type\n",
    "site_override = None\n",
    "\n",
    "if site_override:\n",
    "    site = site_override\n",
    "else:\n",
    "    site = fablib.get_random_site(filter_function=lambda x: x[column_name] > 0)\n",
    "print(f'Preparing to create slice \"{slice_name}\" with node {node_name} in site {site}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the desired slice with a GPU component. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Slice. Note that by default submit() call will poll for 360 seconds every 10-20 seconds\n",
    "# waiting for slice to come up. Normal expected time is around 2 minutes. \n",
    "slice = fablib.new_slice(name=slice_name)\n",
    "\n",
    "# Add node with a 100G drive and a couple of CPU cores (default)\n",
    "node = slice.add_node(name=node_name, site=site, disk=100, image='default_ubuntu_22')\n",
    "node.add_component(model=GPU_CHOICE, name='gpu1')\n",
    "\n",
    "#Submit Slice Request\n",
    "slice.submit();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Slice\n",
    "\n",
    "Retrieve the node information and save the management IP addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = fablib.get_slice(name=slice_name)\n",
    "slice.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Node\n",
    "\n",
    "Retrieve the node information and save the management IP address.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node = slice.get_node(node_name) \n",
    "node.show()\n",
    "\n",
    "gpu = node.get_component('gpu1')\n",
    "gpu.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU PCI Device\n",
    "\n",
    "Run the command <code>lspci</code> to see your GPU PCI device(s). This is the raw GPU PCI device that is not yet configured for use.  You can use the GPUs as you would any GPUs.\n",
    "\n",
    "View node's GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"sudo apt-get install -y pciutils && lspci | grep 'NVIDIA|3D controller'\"\n",
    "\n",
    "stdout, stderr = node.execute(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Nvidia Drivers\n",
    "\n",
    "Now, let's run the following commands to install the latest NVidia driver and the CUDA libraries and compiler. This step can take up to 20 minutes.\n",
    "\n",
    "NOTE: for instructional purposes the following cell sends all command output back to the notebook. You can also send it to log files to keep the notebook output clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "distro='ubuntu2204'\n",
    "version='12.6'\n",
    "architecture='x86_64'\n",
    "\n",
    "# install prerequisites\n",
    "commands = [\n",
    "    'sudo apt-get -q update',\n",
    "    'sudo apt-get -q install -y linux-headers-$(uname -r) gcc',\n",
    "]\n",
    "\n",
    "print(\"Installing Prerequisites...\")\n",
    "for command in commands:\n",
    "    print(f\"++++ {command}\")\n",
    "    stdout, stderr = node.execute(command)\n",
    "\n",
    "print(\"Installing PyTorch...\")\n",
    "commands = [\n",
    "    'sudo apt install python3-pip -y',\n",
    "    'pip3 install torch',\n",
    "    'pip3 install torchvision'\n",
    "]\n",
    "for command in commands:\n",
    "    print(f\"++++ {command}\")\n",
    "    stdout, stderr = node.execute(command)\n",
    "\n",
    "print(f\"Installing CUDA {version}\")\n",
    "commands = [\n",
    "    f'wget https://developer.download.nvidia.com/compute/cuda/repos/{distro}/{architecture}/cuda-keyring_1.1-1_all.deb',\n",
    "    f'sudo dpkg -i cuda-keyring_1.1-1_all.deb',\n",
    "    f'sudo apt-get -q update',\n",
    "    f'sudo apt-get -q install -y cuda-{version.replace(\".\", \"-\")}'\n",
    "]\n",
    "print(\"Installing CUDA...\")\n",
    "for command in commands:\n",
    "    print(f\"++++ {command}\")\n",
    "    stdout, stderr = node.execute(command)\n",
    "    \n",
    "print(\"Done installing CUDA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And once CUDA is installed, reboot the machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reboot = 'sudo reboot'\n",
    "\n",
    "print(reboot)\n",
    "node.execute(reboot)\n",
    "\n",
    "slice.wait_ssh(timeout=360,interval=10,progress=True)\n",
    "\n",
    "print(\"Now testing SSH abilites to reconnect...\",end=\"\")\n",
    "slice.update()\n",
    "slice.test_ssh()\n",
    "print(\"Reconnected!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the GPU and CUDA Installation\n",
    "\n",
    "First, verify that the Nvidia drivers recognize the GPU by running `nvidia-smi`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout, stderr = node.execute(\"nvidia-smi\")\n",
    "\n",
    "print(f\"stdout: {stdout}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA Hello World Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's upload the following \"Hello World\" CUDA program file to the node.\n",
    "\n",
    "`hello-world.cu`\n",
    "\n",
    "*Source: https://computer-graphics.se/multicore/pdf/hello-world.cu*\n",
    "\n",
    "*Author: Ingemar Ragnemalm*\n",
    "\n",
    ">This file is from *\"The real \"Hello World!\" for CUDA, OpenCL and GLSL!\"* (https://computer-graphics.se/hello-world-for-cuda.html), written by Ingemar Ragnemalm, programmer and CUDA teacher. The only changes (if you download the original file from the website) are to additionally `#include <unistd.h>`, as `sleep()` is now a fuction defined in the `unistd.h` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.upload_file('./hello-world.cu', 'hello-world.cu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compile the `.cu` file using `nvcc`, the CUDA compiler tool installed with CUDA. In this example, we create an executable called `hello_world`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout, stderr = node.execute(f\"/usr/local/cuda-{version}/bin/nvcc -o hello_world hello-world.cu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run the executable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout, stderr = node.execute(\"./hello_world\")\n",
    "\n",
    "print(f\"stdout: {stdout}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see `Hello World!`, the CUDA program ran successfully. `World!` was computed on the GPU from an array of offsets being summed with the string `Hello `, and the result was printed to stdout.\n",
    "\n",
    "### Congratulations! You have now successfully run a program on a FABRIC GPU!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch CIFAR10 Classifier Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's follow the \"Training a Classifer\" tutorial from PyTorch to train an image classifier on the CIFAR10 dataset\n",
    "\n",
    "`pytorch_example`\n",
    "\n",
    "*Source: https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node.upload_file('./pytorch_example.py', 'pytorch_example.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run the python script to train and test the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdout, stderr = node.execute(\"python3 pytorch_example.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you see `Finished Training` followed by the accuracy of the classifier, then the script ran successfully.\n",
    "\n",
    "### Congratulations! You have now successfully trained a PyTorch classifier on a FABRIC GPU!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup Your Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fablib.delete_slice(slice_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
